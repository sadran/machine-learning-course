{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework #2: Linear Regression\n",
    "\n",
    "In this homework you will learn the concepts of linear regression by implementing it.\n",
    "\n",
    "Implement the body of each function and test whether you have done right for each of them or not by running the tests. Each function has a test code block just below its definition.\n",
    "\n",
    "- Remember: **m** = number of data items (size of the data set) and **n** = number of features\n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import what we need\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Function\n",
    "\n",
    "For a single data item $ x_{1 \\times n} $, the hypothesis is the linear product of $ w_{n \\times 1} $ and $ x_{1 \\times n} $ in addition to bias $ b_{1 \\times 1} $. The result is a number:\n",
    "\n",
    "$$ h_{w,b}(x) = w^Tx + b $$\n",
    "\n",
    "For a data set $ X_{m \\times n} $ which contains multiple data items stacking vertically, the result is a vector $ h_{m \\times 1} $ which contains predections for all data items:\n",
    "\n",
    "$$ h_{w,b}(X) = Xw + b $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def h(X, w, b):\n",
    "    \"\"\"\n",
    "    The hypothesis function\n",
    "    \n",
    "    X: the data set matrix (m x n)\n",
    "    w: the weights vector (n x 1)\n",
    "    b: the bias (1 x 1)\n",
    "    \n",
    "    Return: a vector stacking predictions for all data items (m x 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE GOES HERE (~ 1 line)\n",
    "    return X.dot(w)+b\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypothesis ok.\n"
     ]
    }
   ],
   "source": [
    "# test the hypothesis\n",
    "\n",
    "X, y, w, b = (np.array([[1, 2, 3], [4, 5, 6]]), np.array([[2], [3]]), np.array([[3], [4], [5]]), 5)\n",
    "\n",
    "hyp = h(X, w, b)\n",
    "true = np.array([[31], [67]])\n",
    "\n",
    "assert hyp.shape == (X.shape[0], 1), \\\n",
    "       'The result should be in shape ({}, 1). Currently is {}'.format(X.shape[0], hyp.shape)\n",
    "\n",
    "if np.allclose(hyp, true):\n",
    "    print('Hypothesis ok.')\n",
    "else:\n",
    "    print('Hypothesis does not work properly.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Function\n",
    "\n",
    "Cost function for a linear regression model is [Mean Squared Error](https://en.wikipedia.org/wiki/Mean_squared_error) over data set:\n",
    "\n",
    "$$ \\begin{equation}\n",
    "   \\begin{split}\n",
    "   J_{w,b}(X) &= \\frac{1}{2m}\\sum_{i=1}^m (h_{w,b}(x^{(i)}) - y^{(i)})^2 \\\\\n",
    "   &= \\frac{1}{2m}\\sum_{i=1}^m (\\hat{y}^{(i)} - y^{(i)})^2\n",
    "   \\end{split}\n",
    "   \\end{equation} $$\n",
    "\n",
    "The goal of linear regression is to minimize this cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Mean squared error cost function\n",
    "    \n",
    "    y_true: the vector of true labels of data items (m x 1)\n",
    "    y_pred: the vector of predictions of data items (m x 1)\n",
    "    \n",
    "    Return: a single number representing the cost\n",
    "    \"\"\"\n",
    "    # YOUR CODE GOES HERE (~ 2 lines)\n",
    "    return  np.sum(( y_pred - y_true)**2) / (2*y_true.shape[0])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost function ok.\n"
     ]
    }
   ],
   "source": [
    "# test cost function\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X, y, w, b = (np.array([[1, 2, 3], [4, 5, 6]]), np.array([[2], [3]]), np.array([[3], [4], [5]]), 5)\n",
    "\n",
    "mse = mean_squared_error(y, h(X, w, b))\n",
    "cst = cost(y, h(X, w, b))\n",
    "\n",
    "if np.isclose(mse / 2, cst):\n",
    "    print('Cost function ok.')\n",
    "else:\n",
    "    print('Cost function does not work properly.')\n",
    "    print('Should\\'ve returned:', mse / 2)\n",
    "    print('Returned:', cst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "\n",
    "Gradient descent algorithm tries to find the minimum of a function by starting somewhere on the function and taking small steps through the gradient of the function.\n",
    "\n",
    "In linear regression, the function we are trying to minimize is the cost function $ J_{w,b}(X) $. The derivations are:\n",
    "\n",
    "$$ \\begin{equation}\n",
    "   \\begin{split}\n",
    "       \\frac{\\partial J_{w,b}(X)}{\\partial w_j} &= \\frac{\\partial}{\\partial w_j} \\frac{1}{2m}\\sum_{i=1}^m (h_{w,b}(x^{(i)}) - y^{(i)})^2 \\\\\n",
    "       &= \\frac{1}{2m}\\sum_{i=1}^m 2 (h_{w,b}(x^{(i)}) - y^{(i)}) \\frac{\\partial}{\\partial w_j} h_{w,b}(x^{(i)}) \\\\\n",
    "       &= \\frac{1}{m}\\sum_{i=1}^m (h_{w,b}(x^{(i)}) - y^{(i)}) x_{j}^{(i)} \\\\\n",
    "       &= \\frac{1}{m}\\sum_{i=1}^m (\\hat{y}^{(i)} - y^{(i)}) x_{j}^{(i)}\n",
    "   \\end{split}\n",
    "   \\end{equation} $$\n",
    "\n",
    "\n",
    "$$ \\begin{equation}\n",
    "   \\begin{split}\n",
    "       \\frac{\\partial J_{w,b}(X)}{\\partial b} &= \\frac{1}{m}\\sum_{i=1}^m \n",
    "       (h_{w,b}(x^{(i)}) - y^{(i)}) \\frac{\\partial}{\\partial b} h_{w,b}(x^{(i)}) \\\\\n",
    "       &= \\frac{1}{m}\\sum_{i=1}^m (h_{w,b}(x^{(i)}) - y^{(i)}) \\\\\n",
    "       &= \\frac{1}{m}\\sum_{i=1}^m (\\hat{y}^{(i)} - y^{(i)})\n",
    "   \\end{split}\n",
    "   \\end{equation} $$\n",
    "   \n",
    "- Actually these two derivations are the same except that in the second one, $ x_{0}^{(i)} = 1 $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient(X, y_true, y_pred):\n",
    "    \"\"\"\n",
    "    The gradient of cost function\n",
    "    \n",
    "    X: the data set matrix (m x n)\n",
    "    y_true: the vector of true labels of data items (m x 1)\n",
    "    y_pred: the vector of predictions of data items (m x 1)\n",
    "    \n",
    "    Return: vector dJ/dw (n x 1) and number dJ/db (1 x 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE GOES HERE (~ 4 lines)\n",
    "    dJdb = np.sum(y_pred - y_true) / y_true.shape[0]\n",
    "    dJdw = X.T.dot(y_pred - y_true) / y_true.shape[0]\n",
    "    return dJdw, dJdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient function ok.\n"
     ]
    }
   ],
   "source": [
    "X, y, w, b = (np.array([[1, 2, 3], [4, 5, 6]]), np.array([[2], [3]]), np.array([[3], [4], [5]]), 5)\n",
    "\n",
    "true = (np.array([[142.5], [189], [235.5]]), 46.5)\n",
    "res = gradient(X, y, h(X, w, b))\n",
    "\n",
    "if np.allclose(res[0], true[0]) and np.isclose(res[1], true[1]):\n",
    "    print('Gradient function ok.')\n",
    "else:\n",
    "    print('Gradient function is not working properly.')\n",
    "    print('should output:', true)\n",
    "    print('Outputted:', res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_parameters(X, y_true, y_pred, w, b, alpha):\n",
    "    \"\"\"\n",
    "    This function updates parameters w and b according to their derivations.\n",
    "    It should compute the cost function derivations with respect to w and b first,\n",
    "        then take a step for each parameters in w and b.\n",
    "    \n",
    "    X: the data set matrix (m x n)\n",
    "    y_true: the vector of true labels of data items (m x 1)\n",
    "    y_pred: the vector of predictions of data items (m x 1)\n",
    "    w: the weights vector (n x 1)\n",
    "    b: the bias (1 x 1)\n",
    "    alpha: the learning rate\n",
    "    \n",
    "    Returns: the updated parameters w and b\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE GOES HERE (~ 4 lines)\n",
    "    w = w - alpha *gradient(X, y_true, y_pred)[0]\n",
    "    b = b - alpha *gradient(X, y_true, y_pred)[1]\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update parameters function ok.\n"
     ]
    }
   ],
   "source": [
    "# test update_parameters function\n",
    "\n",
    "X, y, w, b = (np.array([[1, 2, 3], [4, 5, 6]]), np.array([[2], [3]]), np.array([[3], [4], [5]]), 5)\n",
    "\n",
    "res = update_parameters(X, y, h(X, w, b), w, b, 0.01)\n",
    "true = (np.array([[1.575], [2.11], [2.645]]), 4.535)\n",
    "\n",
    "if np.allclose(res[0], true[0]) and np.isclose(res[1], true[1]):\n",
    "    print('Update parameters function ok.')\n",
    "else:\n",
    "    print('Update parameters function is not working properly.')\n",
    "    print('should output:', true)\n",
    "    print('Outputted:', res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, alpha, n_iterations):\n",
    "    \"\"\"\n",
    "    The gradient descent algorithm:\n",
    "        1. initialize parameters w and b with zeros (not randoms)\n",
    "        for i in n_iterations:\n",
    "            2. compute the hypothesis h(X, w, b)\n",
    "            3. update the parameters using function update_parameters(X, y_true, y_pred, w, b, alpha)\n",
    "            4. compute the cost and see the cost is decreasing in each step (optional)\n",
    "            \n",
    "    X: the data set matrix (m x n)\n",
    "    y: the vector of true labels of data items (m x 1)\n",
    "    alpha: the learning rate\n",
    "    n_iterations: number of steps gradient descent should take to converge\n",
    "    \n",
    "    Returns: the best parameters w and b gradient descent found at last\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE GOES HERE (~ 7 lines)\n",
    "    b=0\n",
    "    w = np.zeros( (X.shape[1], 1) ) \n",
    "    \n",
    "    for i in range(n_iterations):\n",
    "        y_pred = h(X, w, b)\n",
    "        w, b = update_parameters(X, y, y_pred, w, b, alpha)\n",
    "        print(\"step {}: cost = {}\".format( i, cost(y, y_pred) ) )\n",
    "    return w, b\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: cost = 3.25\n",
      "step 1: cost = 1.02150625\n",
      "step 2: cost = 0.3724632615624999\n",
      "step 3: cost = 0.18296491850639454\n",
      "step 4: cost = 0.12717618524105734\n",
      "step 5: cost = 0.11029580200426725\n",
      "step 6: cost = 0.10474143581298409\n",
      "step 7: cost = 0.10248799882412561\n",
      "step 8: cost = 0.10120055441535392\n",
      "step 9: cost = 0.10019970725776858\n",
      "step 10: cost = 0.099287739678892\n",
      "step 11: cost = 0.09840707781580307\n",
      "step 12: cost = 0.09754092285714971\n",
      "step 13: cost = 0.09668433985015679\n",
      "step 14: cost = 0.09583584602923961\n",
      "step 15: cost = 0.09499496344933775\n",
      "step 16: cost = 0.09416150692468557\n",
      "step 17: cost = 0.09333537685209624\n",
      "step 18: cost = 0.09251649892965995\n",
      "step 19: cost = 0.09170480661447146\n",
      "Gradient descent function ok.\n"
     ]
    }
   ],
   "source": [
    "# test gradient_descent function\n",
    "\n",
    "true = (np.array([[0.11532006], [0.19906458], [0.2828091]]), 0.083744520421231317)\n",
    "res = gradient_descent(X, y, 0.01, 20)\n",
    "\n",
    "if np.allclose(res[0], true[0]) and np.isclose(res[1], true[1]):\n",
    "    print('Gradient descent function ok.')\n",
    "else:\n",
    "    print('Gradient descent function is not working properly.')\n",
    "    print('should output:', true)\n",
    "    print('Outputted:', res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.preprocessing import scale\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "X = X[:, 3].reshape(X.shape[0], 1)\n",
    "X = scale(X)\n",
    "y = y.reshape((y.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train a linear regression model from sklearn\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: cost = 14537.240950226244\n",
      "step 1: cost = 12228.704950640227\n",
      "step 2: cost = 10358.790790975556\n",
      "step 3: cost = 8844.16032164717\n",
      "step 4: cost = 7617.309641491177\n",
      "step 5: cost = 6623.560590564824\n",
      "step 6: cost = 5818.623859314478\n",
      "step 7: cost = 5166.625107001699\n",
      "step 8: cost = 4638.506117628344\n",
      "step 9: cost = 4210.7297362359295\n",
      "step 10: cost = 3864.2308673080734\n",
      "step 11: cost = 3583.5667834765104\n",
      "step 12: cost = 3356.2288755729433\n",
      "step 13: cost = 3172.085170171055\n",
      "step 14: cost = 3022.9287687955252\n",
      "step 15: cost = 2902.1120836813448\n",
      "step 16: cost = 2804.2505687388602\n",
      "step 17: cost = 2724.982741635447\n",
      "step 18: cost = 2660.775801681683\n",
      "step 19: cost = 2608.7681803191326\n",
      "step 20: cost = 2566.6420070154686\n",
      "step 21: cost = 2532.5198066394996\n",
      "step 22: cost = 2504.880824334965\n",
      "step 23: cost = 2482.4932486682924\n",
      "step 24: cost = 2464.359312378287\n"
     ]
    }
   ],
   "source": [
    "# train our linear regression model\n",
    "\n",
    "w, b = gradient_descent(X, y, 0.1, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kargadan/.conda/envs/AI_virtual_env/lib/python3.6/site-packages/matplotlib/font_manager.py:279: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  'Matplotlib is building the font cache using fc-list. '\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f544960b588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the result\n",
    "\n",
    "plt.scatter(X, y, s=10, color='gray')\n",
    "plt.plot(X, h(X, w, b), color='red', label='Ours');\n",
    "plt.plot(X, model.predict(X), color='blue', label='Best');\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our hypothesis should be close to the best hypothesis. If they are not the same, raise `n_iterations` argument for our `gradient_descent` function and be careful of `alpha` the learning rate.\n",
    "\n",
    "How well your linear regression model is? How much happy are you!? :D"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
